{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8d6001a-a523-4c54-9ec3-db4d210474cb",
   "metadata": {},
   "source": [
    "# Karpathy Guide to Build GPT from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa839619-1d1c-41b4-8d48-3ed664dc1cae",
   "metadata": {},
   "source": [
    "The entire tutorial is here https://www.youtube.com/watch?v=kCc8FmEb1nY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "650e1080-c64b-48ea-9e58-2cb20bd25e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-11-06 22:45:53--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8001::154, 2606:50c0:8002::154, 2606:50c0:8003::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8001::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   1.06M  2.61MB/s    in 0.4s    \n",
      "\n",
      "2025-11-06 22:45:53 (2.61 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75807b0a-7352-488e-9333-a8ba23569391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the shakespeare data file\n",
    "with open('input.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "140114ce-b832-4245-99e3-ae3bd61cf9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of characters in the text 1115394\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of characters in the text {len(text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbe75450-9729-4ede-ba42-9adbf9f1d346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6c6d050-9ea7-40d1-be42-51466202f6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "# making a set of the characters and then creating the entire character level vocab for this text\n",
    "characters = sorted(list(set(text)))\n",
    "vocab_size = len(characters)\n",
    "print(''.join(characters))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80d082dc-cd4a-497f-90d0-9bba21027806",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch:i for i,ch in enumerate(characters)}\n",
    "itos = {i:ch for i,ch in enumerate(characters)}\n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of numbers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd84d6a7-fc45-43f1-8fa5-0c1a9ce1931a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "K$&!$ KXK pp.\n"
     ]
    }
   ],
   "source": [
    "print(encode(\"hii there\"))\n",
    "print(decode([23,3,4,2,3,1,23,36,23,1,54,54,8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42350ce9-6ed6-43f4-bb09-bf299d04d974",
   "metadata": {},
   "source": [
    "## Tokenize with Character Level Tokenization the entire Shakespeare Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b46779da-e7d2-4efb-9564-3c67cd0729dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text))\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0945eeee-66fe-4a63-bfa8-2f94ba9a3466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and val\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a6d7b62-86b7-4554-a75c-6ccf10b8639a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we create a block or a \"context\" that the model sees when training\n",
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6f2f372-798d-474d-8da1-134134b04ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target: 47\n",
      "when input is tensor([18, 47]) the target: 56\n",
      "when input is tensor([18, 47, 56]) the target: 57\n",
      "when input is tensor([18, 47, 56, 57]) the target: 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d193e8-d374-4849-ab2a-76a127c843b2",
   "metadata": {},
   "source": [
    "A block size of 8 essentially creates 8 training examples that are used for the transformers to train on. We do training on everything from len 1 to len block_size so that the model sees a variety of texts during training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b2bec7-e928-4f8f-9c54-7900a7c51399",
   "metadata": {},
   "source": [
    "Now we are going to batch this and create our training batches. Since the GPU is really good at parallel processing, we can feed it multiple chunks from the same batch and it can train on them together. These chunks in the same batch are all independent of each other and they are just being processed at the same time, but they do not affect each other in any way.\n",
    "\n",
    "This is where batch size comes in. Batch size is the amount of chunks we are processing at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15720fc5-a39e-4b62-9eb1-69d026941e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "----\n",
      "when input is [24] the target: 43\n",
      "when input is [24, 43] the target: 58\n",
      "when input is [24, 43, 58] the target: 5\n",
      "when input is [24, 43, 58, 5] the target: 57\n",
      "when input is [24, 43, 58, 5, 57] the target: 1\n",
      "when input is [24, 43, 58, 5, 57, 1] the target: 46\n",
      "when input is [24, 43, 58, 5, 57, 1, 46] the target: 43\n",
      "when input is [24, 43, 58, 5, 57, 1, 46, 43] the target: 39\n",
      "when input is [44] the target: 53\n",
      "when input is [44, 53] the target: 56\n",
      "when input is [44, 53, 56] the target: 1\n",
      "when input is [44, 53, 56, 1] the target: 58\n",
      "when input is [44, 53, 56, 1, 58] the target: 46\n",
      "when input is [44, 53, 56, 1, 58, 46] the target: 39\n",
      "when input is [44, 53, 56, 1, 58, 46, 39] the target: 58\n",
      "when input is [44, 53, 56, 1, 58, 46, 39, 58] the target: 1\n",
      "when input is [52] the target: 58\n",
      "when input is [52, 58] the target: 1\n",
      "when input is [52, 58, 1] the target: 58\n",
      "when input is [52, 58, 1, 58] the target: 46\n",
      "when input is [52, 58, 1, 58, 46] the target: 39\n",
      "when input is [52, 58, 1, 58, 46, 39] the target: 58\n",
      "when input is [52, 58, 1, 58, 46, 39, 58] the target: 1\n",
      "when input is [52, 58, 1, 58, 46, 39, 58, 1] the target: 46\n",
      "when input is [25] the target: 17\n",
      "when input is [25, 17] the target: 27\n",
      "when input is [25, 17, 27] the target: 10\n",
      "when input is [25, 17, 27, 10] the target: 0\n",
      "when input is [25, 17, 27, 10, 0] the target: 21\n",
      "when input is [25, 17, 27, 10, 0, 21] the target: 1\n",
      "when input is [25, 17, 27, 10, 0, 21, 1] the target: 54\n",
      "when input is [25, 17, 27, 10, 0, 21, 1, 54] the target: 39\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 #how many independent sequences will we process in parallel\n",
    "block_size = 8 # this is the maximum context length for predictions\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix]) # becomes a tensor stack of shape 4,8\n",
    "    y = torch.stack([data[i+1:i+1+block_size] for i in ix])\n",
    "    return x,y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): #batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90772685-84ab-4a88-a44a-712e78933924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n"
     ]
    }
   ],
   "source": [
    "print(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5d5e3d-49e5-4899-9080-16b24b1f76b8",
   "metadata": {},
   "source": [
    "## Creating a simple Bigram Language Model (check out Makemore series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84c35f63-f9c1-49dd-b4a3-348fb7c98e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.8786, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "\n",
    "        B, T, C = logits.shape\n",
    "        logits = logits.view(B*T, C)\n",
    "        targets = targets.view(-1)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "        \n",
    "    def generate(self, idx, \n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e56927d-7706-4b42-88d6-6f2b4fe4a9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(47)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(out[1,1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43a6550e-a363-4f83-9b5c-bc24ada50031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1170, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(out[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00f6c2c9-6e47-4d64-a38f-894c309ab625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1324, -0.5489,  0.1024, -0.6916,  0.3507,  1.6147,  1.8203,  0.5122,\n",
       "         1.5810, -2.0063, -1.2925,  0.1268,  1.1099, -0.6592,  0.8084,  1.9072,\n",
       "        -0.3260, -0.3438, -1.4415, -0.1828, -0.8804, -0.6192, -1.4047, -0.8584,\n",
       "        -0.3830, -0.5372, -1.2176, -1.9403, -0.3094,  0.1790,  1.2859,  0.3039,\n",
       "         1.8110,  0.6350, -0.0820, -2.1208,  1.2516, -0.6826,  0.3838,  0.0150,\n",
       "        -0.2801,  1.4896, -0.4646, -1.9210, -0.1062,  1.0614,  0.9308,  3.1170,\n",
       "        -1.5428, -2.2848,  0.5755, -0.8040,  0.8010,  0.0088, -0.4751, -0.9630,\n",
       "        -0.5078,  0.1018,  1.9141, -1.9252, -1.5554, -0.1878, -0.8599, -1.6050,\n",
       "        -0.6985], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc6d936-c7b0-40d4-a9ce-52b98844a4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
